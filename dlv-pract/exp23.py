import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np

# Define the device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Hyperparameters
batch_size = 64
latent_dim = 100  # Size of the noise vector
epochs = 10000
lr = 0.0002
beta1 = 0.5  # Beta1 parameter for Adam optimizer

# Data transformations and loading MNIST dataset
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])
])

# MNIST dataset loading
dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)
dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)

# Define the Generator Model
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(latent_dim, 256),
            nn.ReLU(True),
            nn.Linear(256, 512),
            nn.ReLU(True),
            nn.Linear(512, 1024),
            nn.ReLU(True),
            nn.Linear(1024, 28*28),
            nn.Tanh()  # Output image range [-1, 1]
        )

    def forward(self, z):
        return self.model(z).view(z.size(0), 1, 28, 28)  # Reshape into image dimensions

# Define the Discriminator Model
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(28*28, 1024),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(1024, 512),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(256, 1),
            nn.Sigmoid()  # Output probability of being real/fake
        )

    def forward(self, x):
        x = x.view(x.size(0), -1)  # Flatten the image
        return self.model(x)

# Create the Generator and Discriminator
generator = Generator().to(device)
discriminator = Discriminator().to(device)

# Loss and optimizers
criterion = nn.BCELoss()  # Binary Cross-Entropy loss for GANs
optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))
optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))

# Training loop
fixed_noise = torch.randn(64, latent_dim, device=device)  # Fixed noise for visualization
real_label = 1
fake_label = 0

def train_gan():
    for epoch in range(epochs):
        for i, (imgs, _) in enumerate(dataloader):
            batch_size = imgs.size(0)
            imgs = imgs.to(device)

            # Create the labels for real and fake images
            real_labels = torch.full((batch_size,), real_label, device=device)
            fake_labels = torch.full((batch_size,), fake_label, device=device)

            # Train Discriminator with real images
            optimizer_D.zero_grad()
            output = discriminator(imgs)
            d_loss_real = criterion(output.view(-1), real_labels)
            d_loss_real.backward()

            # Train Discriminator with fake images generated by the Generator
            z = torch.randn(batch_size, latent_dim, device=device)
            fake_imgs = generator(z)
            output = discriminator(fake_imgs.detach())
            d_loss_fake = criterion(output.view(-1), fake_labels)
            d_loss_fake.backward()

            optimizer_D.step()

            # Train Generator to fool the Discriminator
            optimizer_G.zero_grad()
            output = discriminator(fake_imgs)
            g_loss = criterion(output.view(-1), real_labels)
            g_loss.backward()

            optimizer_G.step()

        # Print the progress and visualize generated images every 5 epochs
        if epoch % 5 == 0:
            print(f"Epoch [{epoch}/{epochs}], D Loss: {d_loss_real.item() + d_loss_fake.item()}, G Loss: {g_loss.item()}")
            with torch.no_grad():
                fake_images = generator(fixed_noise).cpu()
                save_generated_images(fake_images, epoch)

# Function to save and visualize generated images
def save_generated_images(images, epoch, num_images=64):
    images = images.detach().numpy()
    images = np.transpose(images, (0, 2, 3, 1))  # Convert to (batch_size, H, W, C)
    images = (images + 1) / 2  # Rescale to [0, 1]
    fig, axes = plt.subplots(8, 8, figsize=(8, 8), sharex=True, sharey=True)
    for i in range(8):
        for j in range(8):
            axes[i, j].imshow(images[i * 8 + j])
            axes[i, j].axis('off')
    plt.tight_layout_
